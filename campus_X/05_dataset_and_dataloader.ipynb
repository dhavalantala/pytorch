{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=100, \n",
    "    n_features=10,\n",
    "    n_informative=2, \n",
    "    n_redundant=0,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3727107 , -2.42387933,  0.76041466,  1.07954187, -1.88954073,\n",
       "        -0.44618343, -0.45230632,  0.78580016, -1.58390282,  0.42545756],\n",
       "       [ 2.36867367, -0.53086877,  1.04416088,  2.25661188,  1.18839327,\n",
       "        -0.0164229 ,  2.52693243,  0.68189149, -0.48943944,  1.84670733],\n",
       "       [-0.05319823,  0.44426331,  1.1593298 ,  1.85605469, -0.37482081,\n",
       "        -0.2403254 ,  0.71095997, -1.08106333, -0.36096617,  0.61593561],\n",
       "       [ 0.93343952,  1.45338448, -0.52286003,  0.68811892, -0.36283856,\n",
       "         2.29889812, -0.44550252, -0.42018682,  1.57957215, -0.28178461],\n",
       "       [-1.15806823, -0.37144087, -0.77781669,  0.86561977, -2.07339023,\n",
       "         1.24608519, -0.34268759, -1.11057585, -1.40751169,  1.75227044],\n",
       "       [ 1.28008347,  0.8896308 ,  1.06548038,  1.28938375, -1.48556037,\n",
       "         1.03184454,  0.26705027, -0.51728845,  0.08228399,  1.40934744],\n",
       "       [-1.40735658,  0.62834551, -0.89725437, -1.56826626,  0.79166269,\n",
       "         1.15811087,  0.62411982,  0.07580456, -0.01224677, -0.67716171],\n",
       "       [ 0.25415746,  0.33366211, -0.5100164 , -1.79532002, -0.47765745,\n",
       "         0.07156624,  0.47897983, -0.26987494,  1.03753994, -0.97876372],\n",
       "       [ 0.71479373, -0.2209696 ,  0.75750771, -1.42922002,  0.21397991,\n",
       "        -0.69972551, -0.11232805, -0.53050115,  0.6141667 , -0.57581824],\n",
       "       [-0.15013844, -1.4307751 , -0.68105166, -0.11708689,  1.80094043,\n",
       "        -0.6763923 , -0.04015795,  0.84064355,  0.12810441, -0.65262398],\n",
       "       [-1.65830375, -1.24778318, -1.43014138, -1.57127256, -1.02438764,\n",
       "        -3.24126734, -0.25256815, -0.44004449,  1.6324113 ,  0.13074058],\n",
       "       [-0.79371387, -0.59937502,  0.04698059, -0.9311259 ,  1.23781631,\n",
       "        -0.11453985, -1.59442766, -0.45006547,  0.0052437 ,  0.62284993],\n",
       "       [ 0.06845616, -0.79689526, -0.20304539, -1.73597973,  1.44156862,\n",
       "         0.52980418, -2.4716445 ,  0.37114587,  0.57707213, -0.60398519],\n",
       "       [ 1.98522348, -0.48712538, -0.86399077, -0.02185231,  0.56296924,\n",
       "        -1.39856757, -0.65064257,  0.04852163, -0.59239392, -0.83095012],\n",
       "       [ 0.86199147, -0.38770156,  0.33445679,  1.35970566,  1.79587767,\n",
       "         1.5475052 , -0.61278869,  0.65854427,  0.28586539,  2.01020454],\n",
       "       [-1.20757158, -0.65160035,  0.63391902, -1.26898369,  0.21645859,\n",
       "        -0.73036663,  0.04557184, -2.02514259,  2.14394409,  0.18645431],\n",
       "       [ 2.52983424, -0.06575026,  1.88115707,  1.94087643,  0.37721188,\n",
       "        -0.55892185,  1.56552403, -1.4480139 , -0.55519953, -2.19880596],\n",
       "       [-1.17762637,  0.15039379,  1.87617084, -1.20592943, -0.52575502,\n",
       "        -2.12389572, -0.75913266,  0.95042384,  0.34175598, -0.57690366],\n",
       "       [ 1.53313849, -0.73093004,  1.79455786,  1.74147706, -0.79829724,\n",
       "        -0.17694723, -1.37931923, -0.5176113 , -0.03312697,  0.22378795],\n",
       "       [-2.2813861 ,  0.98269098,  1.01437007, -0.1368559 ,  0.47259748,\n",
       "         1.02915564,  0.25602973, -1.84087423,  1.66547444, -1.27957697],\n",
       "       [ 1.2798899 , -0.68198425, -0.28110029,  1.25896077, -2.04173487,\n",
       "         0.20838281, -0.24717738,  1.79768653, -1.00162001,  0.64084286],\n",
       "       [-0.56772453, -0.8946073 , -0.43973106,  1.38991764, -0.47874862,\n",
       "         0.22213377,  1.25575613,  1.44697788, -0.18687164,  0.19655478],\n",
       "       [-0.38566776,  0.30729952,  0.62962884,  0.01722979, -0.6929096 ,\n",
       "         0.35701549,  0.89959988, -0.82899501,  0.81286212, -0.56018104],\n",
       "       [ 1.35536951,  1.4437646 ,  1.11729583,  1.15509316,  0.3520554 ,\n",
       "        -0.24123606, -1.25153942,  0.34272535, -0.08215118,  0.45675322],\n",
       "       [ 1.80474148, -0.19033868, -1.38279973, -0.14994102,  0.53891004,\n",
       "         1.52312408, -1.03724615,  0.92617755, -0.87561825,  1.90941664],\n",
       "       [-0.57500215,  0.18334201, -0.80829829, -0.3751207 , -0.76734756,\n",
       "         2.15318246,  0.87232064, -0.83972184,  2.18980293, -0.59939265],\n",
       "       [ 1.31217492, -0.38455554, -0.57689187, -0.7173148 ,  0.04739867,\n",
       "        -0.65183611, -0.86041337,  0.83569211,  1.00629281, -1.12970685],\n",
       "       [-1.21722043,  0.81350964,  0.02100384, -1.36716377,  1.09877685,\n",
       "        -0.2176812 ,  0.82541635,  0.68195297,  1.30547881, -0.31026676],\n",
       "       [-2.02632079, -0.51604473, -0.46227529,  0.06194498,  0.02975614,\n",
       "         0.02831838,  0.93828381, -0.43449623,  0.09612078, -0.30917212],\n",
       "       [ 1.86378908, -1.0265153 , -0.70012081,  1.59488828,  0.19408999,\n",
       "        -0.44643361,  1.07363175,  1.19504663,  0.13296967, -1.5231869 ],\n",
       "       [ 0.96423311, -1.07008477, -0.69190807,  0.55600276, -0.09917586,\n",
       "         0.65020118,  1.846637  , -0.04558602, -1.52552517,  0.24333945],\n",
       "       [-0.34898484, -1.25111358, -0.18490214,  1.56010259, -0.30954644,\n",
       "         0.59310126,  0.32613302, -0.52272302,  0.92402702,  1.04900923],\n",
       "       [-1.36045573,  0.66213067, -1.2378155 , -1.64060704, -0.3853136 ,\n",
       "         0.06980208,  0.11351735,  2.13303337,  1.58601682, -1.9520878 ],\n",
       "       [-1.4117586 , -0.70766947,  0.77463405, -1.5332749 , -0.48423407,\n",
       "        -1.51936997,  1.26691115, -0.92693047,  0.44381943, -0.05952536],\n",
       "       [-0.07133524,  1.0889506 , -1.07774478,  0.08896214, -1.61271587,\n",
       "         0.68626019, -0.47193187, -0.71530371,  0.06428002,  0.67959775],\n",
       "       [ 1.15199146,  0.71754226,  0.07409478, -0.71352532, -2.03923218,\n",
       "        -1.18325851, -0.26940683,  1.62861555,  1.50235705, -1.38010146],\n",
       "       [-0.50833095,  0.39913611,  1.10330188,  1.48052803, -0.09671311,\n",
       "         0.21101747, -0.54491909,  0.11422765, -0.0376347 ,  0.15030176],\n",
       "       [-1.75518644,  1.0536418 ,  2.63238206,  0.36016958, -1.35168461,\n",
       "        -0.92323325, -0.97587325,  0.4933179 , -0.94939889,  0.18483612],\n",
       "       [-1.40210053,  0.59515703,  2.09238728, -1.72067112, -0.13014305,\n",
       "         0.32416635,  0.09699596, -1.00601738, -0.81822068, -1.21418861],\n",
       "       [-0.53963044, -0.32138584, -0.56372455, -0.72427983, -0.14705738,\n",
       "         0.97511973, -0.8254972 , -0.8222204 ,  0.41293145,  0.24368721],\n",
       "       [ 1.08266027, -1.03524232, -1.19787789, -0.98021491, -0.79287283,\n",
       "        -0.53025762, -0.10703036,  1.96472513, -0.55364931,  0.03526355],\n",
       "       [-1.69302842,  1.53273891,  0.40171172, -1.61453273, -0.82723094,\n",
       "         0.32271856,  0.51934651,  0.69014399, -0.10876015, -0.40122047],\n",
       "       [-0.80804463, -0.24751864,  0.6206721 ,  1.19664076, -1.57022472,\n",
       "         0.62180996, -0.72713718,  0.177701  , -0.07443343, -1.33534436],\n",
       "       [ 1.09885263,  1.32915253,  0.70900376,  1.25291095,  0.44770856,\n",
       "         0.56976728,  0.64272276, -0.08973569,  0.19652117,  1.44011722],\n",
       "       [ 0.07123641, -0.11473644,  0.86575519,  0.49429823,  0.85243333,\n",
       "        -0.66178646, -0.79252074, -1.20029641,  0.50498728, -0.33450124],\n",
       "       [ 1.56070438,  0.77086519,  1.14375404, -0.42795824, -2.21113531,\n",
       "         0.82940558,  0.23561456,  0.33849641, -1.47858625, -0.41528791],\n",
       "       [-1.54851014,  0.51443883, -1.12464209, -1.43534875, -0.14237949,\n",
       "        -1.06762043,  0.12029563, -1.53411417,  0.71161488,  1.27767682],\n",
       "       [ 0.55942643,  1.66902153, -1.50314295,  2.38869353, -1.29507877,\n",
       "        -1.2899609 , -0.3357847 , -0.24574306, -0.25959135, -0.27272357],\n",
       "       [ 1.65882246,  1.36863156,  0.68605146, -0.43131517,  0.97157095,\n",
       "        -0.24896415,  0.64537595,  1.05842449, -0.96492346, -1.75873949],\n",
       "       [ 0.68057323,  0.70835645, -0.56407863,  1.02703224, -0.50205422,\n",
       "         0.44001445, -1.02123282, -1.2803044 ,  0.24380071,  0.87245733],\n",
       "       [ 1.03967019, -0.92216532,  1.35563786, -0.92169432,  0.37730049,\n",
       "        -0.44429326,  0.75698862,  0.4134349 ,  0.86960592,  1.87679581],\n",
       "       [-0.27062383, -0.90431663, -1.66152006, -2.25553963,  0.04808495,\n",
       "        -1.62754244,  0.2597225 , -0.0660798 ,  0.63859246, -1.2110162 ],\n",
       "       [-1.87653774, -0.72574381, -0.75538293,  0.23085877,  0.02609105,\n",
       "        -0.62481858,  0.51765902, -0.6115178 ,  0.18676676, -1.4066611 ],\n",
       "       [ 0.32725188, -1.15836469,  0.87736229,  0.62453032, -0.04771136,\n",
       "        -0.96697614, -0.00360254, -0.22096417,  1.5033983 ,  0.02688584],\n",
       "       [ 0.15513175,  0.60600995,  1.75479418,  1.99805321, -1.4084613 ,\n",
       "        -0.70434369, -1.55662917, -2.08192941, -1.28042935,  1.69645637],\n",
       "       [-1.43483867,  0.23204994, -1.40746377, -1.42695838, -0.50694318,\n",
       "         0.24496657, -0.47103831, -0.71844422, -1.44808434, -0.21344715],\n",
       "       [-1.09831681, -0.15993853, -1.00252936, -0.86023823,  1.47535622,\n",
       "         0.31090757,  0.85765962, -0.01851314, -0.01901621, -0.28865864],\n",
       "       [-0.78284083, -1.27674858,  1.05315285,  1.20852705,  0.20768769,\n",
       "         0.42961822,  0.27157884, -0.03955515, -1.08105654,  0.6815007 ],\n",
       "       [ 1.46830827, -1.05921352,  0.95514232, -0.48949935, -0.93987979,\n",
       "         0.36659825, -0.51386692, -0.98572605, -0.0626791 ,  0.50404652],\n",
       "       [-2.00918545, -0.62269952, -0.49300093, -2.24181979,  0.58831721,\n",
       "        -0.1517851 ,  0.28099187, -0.58936476, -0.20812225,  0.8496021 ],\n",
       "       [ 1.17329352,  0.47141556,  0.63293182,  0.73644435, -0.57074629,\n",
       "         1.42050425, -0.83235557,  0.20292302, -0.55222304, -1.51574411],\n",
       "       [ 0.6273745 ,  0.11567463,  0.06751848, -1.32933233, -0.74848654,\n",
       "         0.33231401,  1.55115198,  2.06074792,  1.17929718,  1.75534084],\n",
       "       [-1.82037691, -1.71016839,  0.74326409,  0.25995672, -0.05694562,\n",
       "        -0.36361221,  0.30780177,  0.17086544, -1.34818542, -0.18398334],\n",
       "       [-0.78736523,  0.69620636,  1.12656503,  1.18739045, -0.05429487,\n",
       "        -2.69688664, -0.23093453, -0.26888869,  1.84895609, -1.10652591],\n",
       "       [-0.91916686, -0.77830473, -0.97837278,  1.06173727,  0.34758171,\n",
       "         0.01843393, -0.53975968,  0.40825276,  0.19584526, -1.7025836 ],\n",
       "       [ 1.65214494, -0.95554044,  0.20346364, -0.35885569,  1.11957491,\n",
       "         3.07888081, -0.12791759, -0.75635075, -1.60644632, -1.42225371],\n",
       "       [ 1.08659413,  0.24822059, -0.84984437, -1.00544254,  2.27069286,\n",
       "         0.63278187,  0.18186626,  0.83033582, -0.4593609 , -0.85608383],\n",
       "       [-1.00634985,  0.40498171,  0.91786195, -1.14054824, -0.65332923,\n",
       "        -0.47494531,  1.76545424,  2.1221562 , -1.26088395,  1.03246526],\n",
       "       [ 0.480502  ,  1.10870358,  0.50727403,  0.54914434, -0.35929209,\n",
       "         0.58392819,  0.59065483,  1.06667469,  0.82048218,  1.16929559],\n",
       "       [-2.3279946 ,  1.08078073,  0.45918008, -0.17593681,  0.61058575,\n",
       "         0.38019785,  0.55979045, -0.07016571,  0.83392215, -1.66096093],\n",
       "       [ 0.82584805,  0.92463368, -0.64693678,  0.53479393,  0.57258278,\n",
       "        -0.57117899,  1.39935544,  0.69822331,  0.05963037,  0.39348539],\n",
       "       [-2.05832072,  0.01023306,  0.46210347, -2.52343407, -1.43586215,\n",
       "         1.44127329,  1.16316375,  0.1990597 , -0.98150865, -0.60021688],\n",
       "       [ 1.03110238, -0.53099696, -0.55547712,  0.55448398,  2.45530014,\n",
       "         0.28916864, -0.63773998, -0.63738713, -0.62314053,  1.18901653],\n",
       "       [-1.28568005, -0.51121568, -0.12578692,  0.73019848,  1.34542005,\n",
       "         1.8820245 ,  1.59318663,  0.05572491, -0.98960482,  1.09419152],\n",
       "       [ 1.53703587, -0.35151348,  1.67643731, -0.53355799, -1.00808631,\n",
       "        -2.03812454, -1.87079192,  0.32692737,  0.01841838, -0.21910053],\n",
       "       [ 1.83991037,  0.67481949,  0.38240975,  2.30450019, -0.21398884,\n",
       "         0.9843224 , -0.04946371,  0.16645221, -1.12272202,  0.49245126],\n",
       "       [ 2.59123946, -0.90756366,  0.75539123,  0.24472415, -0.05023811,\n",
       "         0.27045683, -0.23894805,  0.50091719, -0.57677133, -0.97755524],\n",
       "       [ 0.82600732,  2.0754008 , -0.32602353, -1.05383855, -0.42098448,\n",
       "         0.39445214,  0.28977486,  1.20121392,  0.8711247 , -0.40807537],\n",
       "       [-2.00347738,  1.83145877, -0.46917565, -2.39955005,  0.49191917,\n",
       "        -0.89841467, -1.32023321, -1.71313453,  1.17944012,  1.35387237],\n",
       "       [ 0.25058844,  0.14671369, -0.81693567,  0.13979096,  0.64870989,\n",
       "         1.38215899, -0.16711808,  0.36867331,  1.20650897, -0.39333881],\n",
       "       [ 1.17869556,  0.04643655,  0.74625357,  1.09180466,  1.27845186,\n",
       "         0.02874482,  0.19109907,  0.64548418, -1.35985614,  2.16325472],\n",
       "       [-2.58590856, -0.02412509, -0.14436041, -0.40925706,  0.05921843,\n",
       "         2.5733598 ,  0.01392929, -0.57366201,  0.19808476, -0.54685894],\n",
       "       [ 0.77861318,  0.54336019,  0.57059867, -1.20946429,  0.75138712,\n",
       "         0.09933231, -1.66940528, -0.76325916, -0.66262376, -1.8048821 ],\n",
       "       [-0.94275087,  0.10643023,  1.50399299,  1.10009583, -0.54342477,\n",
       "        -0.03275327, -0.71284578, -2.65096981, -0.25497722,  1.09150685],\n",
       "       [ 0.34129395, -0.53523521,  0.1975996 ,  0.57304248,  0.6351718 ,\n",
       "         0.89519322,  1.04955272,  2.07526087,  1.31739407, -0.68918782],\n",
       "       [ 0.85239186,  1.49604431, -0.05558467, -1.14658127, -1.2446547 ,\n",
       "        -0.7737892 , -1.77872025,  0.27996863,  0.65436566, -1.12548905],\n",
       "       [ 1.02255619,  0.25442084, -0.41187697, -1.08324727, -0.15567724,\n",
       "         0.08658979,  1.16778206, -0.48760622,  0.33760266, -0.43255819],\n",
       "       [ 1.57233676,  1.57745328,  0.27902153,  1.4991983 ,  0.21915033,\n",
       "        -0.30777823,  0.24938368,  0.60789651, -0.09529553,  0.18660912],\n",
       "       [-1.13207427, -0.42688107, -1.65485667,  0.89075877,  1.52955032,\n",
       "        -1.69246463, -0.1580079 ,  0.82317058, -1.01210438,  0.07331797],\n",
       "       [-1.5598485 , -0.77300978,  0.49799829, -1.92487377,  0.0125924 ,\n",
       "         0.22409248,  0.0976761 ,  1.45114361,  0.02451017,  0.95927083],\n",
       "       [-1.54446032,  0.11732738, -0.59157139, -1.51042899,  0.61037027,\n",
       "         0.74729361, -0.02090159,  0.54709738,  1.2776649 , -0.20219265],\n",
       "       [ 0.66530077, -0.76779757,  0.23421473,  0.88629356, -0.91865195,\n",
       "        -1.34445051, -1.00414077,  1.55050049, -0.03468489, -0.99835404],\n",
       "       [-2.17105282,  0.72576662,  0.22388402, -0.04862909,  0.12922118,\n",
       "         2.44575198,  0.10939479, -0.79047446,  0.48100923,  0.47146836],\n",
       "       [ 1.50575249,  1.36687427, -0.24903604, -0.38919817, -2.30192116,\n",
       "        -0.2750517 , -1.51519106,  0.57655696,  1.64496771,  0.31125015],\n",
       "       [-1.64832073,  0.12200981, -0.0960599 ,  0.4176729 ,  0.70030988,\n",
       "        -0.85835778, -0.57563783,  1.14927333,  2.56008454, -0.70317643],\n",
       "       [-1.03223274, -1.12905177,  0.48937456,  0.94800532,  1.27155509,\n",
       "         0.93567839,  0.72167206, -1.22212781, -0.52452027,  0.71299843],\n",
       "       [-0.3313761 ,  1.81244856, -0.56246678,  1.56931739,  1.77080064,\n",
       "        -0.03498849, -0.62696706,  0.63240774,  0.70775194,  0.97255445],\n",
       "       [ 0.4505902 ,  0.88163976,  1.47994414, -1.50077611, -1.081548  ,\n",
       "        -0.64657288,  1.68714164,  0.07736831, -0.00797264, -0.8612842 ],\n",
       "       [-0.81680628, -0.23681861,  0.08187414, -0.6795874 ,  0.75896922,\n",
       "        -0.31526924, -0.77282521,  2.31465857, -0.48536355, -1.86726519],\n",
       "       [ 1.15466088, -0.03269475, -0.08912004, -0.95548162, -0.0555477 ,\n",
       "        -1.70338244,  0.38406545, -1.3044695 , -2.0674421 ,  0.66967255]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(features=X, labels=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " (tensor([ 1.3727, -2.4239,  0.7604,  1.0795, -1.8895, -0.4462, -0.4523,  0.7858,\n",
       "          -1.5839,  0.4255]),\n",
       "  tensor(1)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1501, -1.4308, -0.6811, -0.1171,  1.8009, -0.6764, -0.0402,  0.8406,\n",
      "          0.1281, -0.6526],\n",
      "        [ 0.7786,  0.5434,  0.5706, -1.2095,  0.7514,  0.0993, -1.6694, -0.7633,\n",
      "         -0.6626, -1.8049],\n",
      "        [ 1.5723,  1.5775,  0.2790,  1.4992,  0.2192, -0.3078,  0.2494,  0.6079,\n",
      "         -0.0953,  0.1866],\n",
      "        [ 1.0827, -1.0352, -1.1979, -0.9802, -0.7929, -0.5303, -0.1070,  1.9647,\n",
      "         -0.5536,  0.0353],\n",
      "        [-2.5859, -0.0241, -0.1444, -0.4093,  0.0592,  2.5734,  0.0139, -0.5737,\n",
      "          0.1981, -0.5469]])\n",
      "tensor([1, 1, 1, 1, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 2.5912, -0.9076,  0.7554,  0.2447, -0.0502,  0.2705, -0.2389,  0.5009,\n",
      "         -0.5768, -0.9776],\n",
      "        [-2.1711,  0.7258,  0.2239, -0.0486,  0.1292,  2.4458,  0.1094, -0.7905,\n",
      "          0.4810,  0.4715],\n",
      "        [ 1.0226,  0.2544, -0.4119, -1.0832, -0.1557,  0.0866,  1.1678, -0.4876,\n",
      "          0.3376, -0.4326],\n",
      "        [-1.2076, -0.6516,  0.6339, -1.2690,  0.2165, -0.7304,  0.0456, -2.0251,\n",
      "          2.1439,  0.1865],\n",
      "        [ 1.8638, -1.0265, -0.7001,  1.5949,  0.1941, -0.4464,  1.0736,  1.1950,\n",
      "          0.1330, -1.5232]])\n",
      "tensor([1, 0, 1, 0, 1])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 1.5058,  1.3669, -0.2490, -0.3892, -2.3019, -0.2751, -1.5152,  0.5766,\n",
      "          1.6450,  0.3113],\n",
      "        [ 0.9642, -1.0701, -0.6919,  0.5560, -0.0992,  0.6502,  1.8466, -0.0456,\n",
      "         -1.5255,  0.2433],\n",
      "        [ 0.8620, -0.3877,  0.3345,  1.3597,  1.7959,  1.5475, -0.6128,  0.6585,\n",
      "          0.2859,  2.0102],\n",
      "        [ 0.4805,  1.1087,  0.5073,  0.5491, -0.3593,  0.5839,  0.5907,  1.0667,\n",
      "          0.8205,  1.1693],\n",
      "        [-0.5677, -0.8946, -0.4397,  1.3899, -0.4787,  0.2221,  1.2558,  1.4470,\n",
      "         -0.1869,  0.1966]])\n",
      "tensor([1, 1, 1, 1, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 0.8524,  1.4960, -0.0556, -1.1466, -1.2447, -0.7738, -1.7787,  0.2800,\n",
      "          0.6544, -1.1255],\n",
      "        [ 0.3273, -1.1584,  0.8774,  0.6245, -0.0477, -0.9670, -0.0036, -0.2210,\n",
      "          1.5034,  0.0269],\n",
      "        [-1.6930,  1.5327,  0.4017, -1.6145, -0.8272,  0.3227,  0.5193,  0.6901,\n",
      "         -0.1088, -0.4012],\n",
      "        [-1.5598, -0.7730,  0.4980, -1.9249,  0.0126,  0.2241,  0.0977,  1.4511,\n",
      "          0.0245,  0.9593],\n",
      "        [-0.9428,  0.1064,  1.5040,  1.1001, -0.5434, -0.0328, -0.7128, -2.6510,\n",
      "         -0.2550,  1.0915]])\n",
      "tensor([1, 1, 0, 0, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 2.5298, -0.0658,  1.8812,  1.9409,  0.3772, -0.5589,  1.5655, -1.4480,\n",
      "         -0.5552, -2.1988],\n",
      "        [-1.0983, -0.1599, -1.0025, -0.8602,  1.4754,  0.3109,  0.8577, -0.0185,\n",
      "         -0.0190, -0.2887],\n",
      "        [ 0.6274,  0.1157,  0.0675, -1.3293, -0.7485,  0.3323,  1.5512,  2.0607,\n",
      "          1.1793,  1.7553],\n",
      "        [ 1.0311, -0.5310, -0.5555,  0.5545,  2.4553,  0.2892, -0.6377, -0.6374,\n",
      "         -0.6231,  1.1890],\n",
      "        [-1.4021,  0.5952,  2.0924, -1.7207, -0.1301,  0.3242,  0.0970, -1.0060,\n",
      "         -0.8182, -1.2142]])\n",
      "tensor([1, 0, 1, 1, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-0.8080, -0.2475,  0.6207,  1.1966, -1.5702,  0.6218, -0.7271,  0.1777,\n",
      "         -0.0744, -1.3353],\n",
      "        [ 1.8399,  0.6748,  0.3824,  2.3045, -0.2140,  0.9843, -0.0495,  0.1665,\n",
      "         -1.1227,  0.4925],\n",
      "        [ 0.7148, -0.2210,  0.7575, -1.4292,  0.2140, -0.6997, -0.1123, -0.5305,\n",
      "          0.6142, -0.5758],\n",
      "        [ 1.9852, -0.4871, -0.8640, -0.0219,  0.5630, -1.3986, -0.6506,  0.0485,\n",
      "         -0.5924, -0.8310],\n",
      "        [-1.4074,  0.6283, -0.8973, -1.5683,  0.7917,  1.1581,  0.6241,  0.0758,\n",
      "         -0.0122, -0.6772]])\n",
      "tensor([0, 1, 1, 1, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-1.0063,  0.4050,  0.9179, -1.1405, -0.6533, -0.4749,  1.7655,  2.1222,\n",
      "         -1.2609,  1.0325],\n",
      "        [-1.1321, -0.4269, -1.6549,  0.8908,  1.5296, -1.6925, -0.1580,  0.8232,\n",
      "         -1.0121,  0.0733],\n",
      "        [-0.9192, -0.7783, -0.9784,  1.0617,  0.3476,  0.0184, -0.5398,  0.4083,\n",
      "          0.1958, -1.7026],\n",
      "        [-1.4118, -0.7077,  0.7746, -1.5333, -0.4842, -1.5194,  1.2669, -0.9269,\n",
      "          0.4438, -0.0595],\n",
      "        [ 1.1733,  0.4714,  0.6329,  0.7364, -0.5707,  1.4205, -0.8324,  0.2029,\n",
      "         -0.5522, -1.5157]])\n",
      "tensor([0, 0, 0, 0, 1])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-2.0035,  1.8315, -0.4692, -2.3995,  0.4919, -0.8984, -1.3202, -1.7131,\n",
      "          1.1794,  1.3539],\n",
      "        [-0.3314,  1.8124, -0.5625,  1.5693,  1.7708, -0.0350, -0.6270,  0.6324,\n",
      "          0.7078,  0.9726],\n",
      "        [ 0.6653, -0.7678,  0.2342,  0.8863, -0.9187, -1.3445, -1.0041,  1.5505,\n",
      "         -0.0347, -0.9984],\n",
      "        [-0.7874,  0.6962,  1.1266,  1.1874, -0.0543, -2.6969, -0.2309, -0.2689,\n",
      "          1.8490, -1.1065],\n",
      "        [ 1.0989,  1.3292,  0.7090,  1.2529,  0.4477,  0.5698,  0.6427, -0.0897,\n",
      "          0.1965,  1.4401]])\n",
      "tensor([0, 0, 1, 0, 1])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 1.5607,  0.7709,  1.1438, -0.4280, -2.2111,  0.8294,  0.2356,  0.3385,\n",
      "         -1.4786, -0.4153],\n",
      "        [ 1.0866,  0.2482, -0.8498, -1.0054,  2.2707,  0.6328,  0.1819,  0.8303,\n",
      "         -0.4594, -0.8561],\n",
      "        [ 0.8258,  0.9246, -0.6469,  0.5348,  0.5726, -0.5712,  1.3994,  0.6982,\n",
      "          0.0596,  0.3935],\n",
      "        [-0.0532,  0.4443,  1.1593,  1.8561, -0.3748, -0.2403,  0.7110, -1.0811,\n",
      "         -0.3610,  0.6159],\n",
      "        [-0.2706, -0.9043, -1.6615, -2.2555,  0.0481, -1.6275,  0.2597, -0.0661,\n",
      "          0.6386, -1.2110]])\n",
      "tensor([1, 1, 1, 0, 1])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 1.6588,  1.3686,  0.6861, -0.4313,  0.9716, -0.2490,  0.6454,  1.0584,\n",
      "         -0.9649, -1.7587],\n",
      "        [-1.6483,  0.1220, -0.0961,  0.4177,  0.7003, -0.8584, -0.5756,  1.1493,\n",
      "          2.5601, -0.7032],\n",
      "        [ 1.8047, -0.1903, -1.3828, -0.1499,  0.5389,  1.5231, -1.0372,  0.9262,\n",
      "         -0.8756,  1.9094],\n",
      "        [-2.2814,  0.9827,  1.0144, -0.1369,  0.4726,  1.0292,  0.2560, -1.8409,\n",
      "          1.6655, -1.2796],\n",
      "        [ 0.6806,  0.7084, -0.5641,  1.0270, -0.5021,  0.4400, -1.0212, -1.2803,\n",
      "          0.2438,  0.8725]])\n",
      "tensor([1, 0, 1, 0, 1])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 2.3687, -0.5309,  1.0442,  2.2566,  1.1884, -0.0164,  2.5269,  0.6819,\n",
      "         -0.4894,  1.8467],\n",
      "        [ 0.2542,  0.3337, -0.5100, -1.7953, -0.4777,  0.0716,  0.4790, -0.2699,\n",
      "          1.0375, -0.9788],\n",
      "        [-1.1776,  0.1504,  1.8762, -1.2059, -0.5258, -2.1239, -0.7591,  0.9504,\n",
      "          0.3418, -0.5769],\n",
      "        [-0.7937, -0.5994,  0.0470, -0.9311,  1.2378, -0.1145, -1.5944, -0.4501,\n",
      "          0.0052,  0.6228],\n",
      "        [ 1.6521, -0.9555,  0.2035, -0.3589,  1.1196,  3.0789, -0.1279, -0.7564,\n",
      "         -1.6064, -1.4223]])\n",
      "tensor([1, 1, 0, 0, 1])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-0.5396, -0.3214, -0.5637, -0.7243, -0.1471,  0.9751, -0.8255, -0.8222,\n",
      "          0.4129,  0.2437],\n",
      "        [ 1.2801,  0.8896,  1.0655,  1.2894, -1.4856,  1.0318,  0.2671, -0.5173,\n",
      "          0.0823,  1.4093],\n",
      "        [ 1.4683, -1.0592,  0.9551, -0.4895, -0.9399,  0.3666, -0.5139, -0.9857,\n",
      "         -0.0627,  0.5040],\n",
      "        [ 1.5331, -0.7309,  1.7946,  1.7415, -0.7983, -0.1769, -1.3793, -0.5176,\n",
      "         -0.0331,  0.2238],\n",
      "        [ 0.0712, -0.1147,  0.8658,  0.4943,  0.8524, -0.6618, -0.7925, -1.2003,\n",
      "          0.5050, -0.3345]])\n",
      "tensor([0, 1, 1, 1, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 1.3554,  1.4438,  1.1173,  1.1551,  0.3521, -0.2412, -1.2515,  0.3427,\n",
      "         -0.0822,  0.4568],\n",
      "        [ 1.3122, -0.3846, -0.5769, -0.7173,  0.0474, -0.6518, -0.8604,  0.8357,\n",
      "          1.0063, -1.1297],\n",
      "        [-1.7552,  1.0536,  2.6324,  0.3602, -1.3517, -0.9232, -0.9759,  0.4933,\n",
      "         -0.9494,  0.1848],\n",
      "        [-1.5445,  0.1173, -0.5916, -1.5104,  0.6104,  0.7473, -0.0209,  0.5471,\n",
      "          1.2777, -0.2022],\n",
      "        [-0.8168, -0.2368,  0.0819, -0.6796,  0.7590, -0.3153, -0.7728,  2.3147,\n",
      "         -0.4854, -1.8673]])\n",
      "tensor([1, 1, 0, 0, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 1.5370, -0.3515,  1.6764, -0.5336, -1.0081, -2.0381, -1.8708,  0.3269,\n",
      "          0.0184, -0.2191],\n",
      "        [-1.5485,  0.5144, -1.1246, -1.4353, -0.1424, -1.0676,  0.1203, -1.5341,\n",
      "          0.7116,  1.2777],\n",
      "        [ 0.4506,  0.8816,  1.4799, -1.5008, -1.0815, -0.6466,  1.6871,  0.0774,\n",
      "         -0.0080, -0.8613],\n",
      "        [ 0.3413, -0.5352,  0.1976,  0.5730,  0.6352,  0.8952,  1.0496,  2.0753,\n",
      "          1.3174, -0.6892],\n",
      "        [-1.4348,  0.2320, -1.4075, -1.4270, -0.5069,  0.2450, -0.4710, -0.7184,\n",
      "         -1.4481, -0.2134]])\n",
      "tensor([1, 0, 1, 1, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 0.5594,  1.6690, -1.5031,  2.3887, -1.2951, -1.2900, -0.3358, -0.2457,\n",
      "         -0.2596, -0.2727],\n",
      "        [ 1.2799, -0.6820, -0.2811,  1.2590, -2.0417,  0.2084, -0.2472,  1.7977,\n",
      "         -1.0016,  0.6408],\n",
      "        [ 0.0685, -0.7969, -0.2030, -1.7360,  1.4416,  0.5298, -2.4716,  0.3711,\n",
      "          0.5771, -0.6040],\n",
      "        [-1.3605,  0.6621, -1.2378, -1.6406, -0.3853,  0.0698,  0.1135,  2.1330,\n",
      "          1.5860, -1.9521],\n",
      "        [-2.0263, -0.5160, -0.4623,  0.0619,  0.0298,  0.0283,  0.9383, -0.4345,\n",
      "          0.0961, -0.3092]])\n",
      "tensor([0, 1, 1, 0, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-1.8204, -1.7102,  0.7433,  0.2600, -0.0569, -0.3636,  0.3078,  0.1709,\n",
      "         -1.3482, -0.1840],\n",
      "        [-0.3857,  0.3073,  0.6296,  0.0172, -0.6929,  0.3570,  0.8996, -0.8290,\n",
      "          0.8129, -0.5602],\n",
      "        [ 1.1547, -0.0327, -0.0891, -0.9555, -0.0555, -1.7034,  0.3841, -1.3045,\n",
      "         -2.0674,  0.6697],\n",
      "        [-0.3490, -1.2511, -0.1849,  1.5601, -0.3095,  0.5931,  0.3261, -0.5227,\n",
      "          0.9240,  1.0490],\n",
      "        [-1.0322, -1.1291,  0.4894,  0.9480,  1.2716,  0.9357,  0.7217, -1.2221,\n",
      "         -0.5245,  0.7130]])\n",
      "tensor([0, 0, 1, 0, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-1.2857, -0.5112, -0.1258,  0.7302,  1.3454,  1.8820,  1.5932,  0.0557,\n",
      "         -0.9896,  1.0942],\n",
      "        [ 1.3727, -2.4239,  0.7604,  1.0795, -1.8895, -0.4462, -0.4523,  0.7858,\n",
      "         -1.5839,  0.4255],\n",
      "        [-1.2172,  0.8135,  0.0210, -1.3672,  1.0988, -0.2177,  0.8254,  0.6820,\n",
      "          1.3055, -0.3103],\n",
      "        [-0.7828, -1.2767,  1.0532,  1.2085,  0.2077,  0.4296,  0.2716, -0.0396,\n",
      "         -1.0811,  0.6815],\n",
      "        [ 0.2506,  0.1467, -0.8169,  0.1398,  0.6487,  1.3822, -0.1671,  0.3687,\n",
      "          1.2065, -0.3933]])\n",
      "tensor([0, 1, 0, 0, 1])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[ 0.8260,  2.0754, -0.3260, -1.0538, -0.4210,  0.3945,  0.2898,  1.2012,\n",
      "          0.8711, -0.4081],\n",
      "        [-2.3280,  1.0808,  0.4592, -0.1759,  0.6106,  0.3802,  0.5598, -0.0702,\n",
      "          0.8339, -1.6610],\n",
      "        [ 0.9334,  1.4534, -0.5229,  0.6881, -0.3628,  2.2989, -0.4455, -0.4202,\n",
      "          1.5796, -0.2818],\n",
      "        [-2.0583,  0.0102,  0.4621, -2.5234, -1.4359,  1.4413,  1.1632,  0.1991,\n",
      "         -0.9815, -0.6002],\n",
      "        [-1.8765, -0.7257, -0.7554,  0.2309,  0.0261, -0.6248,  0.5177, -0.6115,\n",
      "          0.1868, -1.4067]])\n",
      "tensor([1, 0, 1, 0, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-1.6583, -1.2478, -1.4301, -1.5713, -1.0244, -3.2413, -0.2526, -0.4400,\n",
      "          1.6324,  0.1307],\n",
      "        [-2.0092, -0.6227, -0.4930, -2.2418,  0.5883, -0.1518,  0.2810, -0.5894,\n",
      "         -0.2081,  0.8496],\n",
      "        [ 1.0397, -0.9222,  1.3556, -0.9217,  0.3773, -0.4443,  0.7570,  0.4134,\n",
      "          0.8696,  1.8768],\n",
      "        [-1.1581, -0.3714, -0.7778,  0.8656, -2.0734,  1.2461, -0.3427, -1.1106,\n",
      "         -1.4075,  1.7523],\n",
      "        [-0.5083,  0.3991,  1.1033,  1.4805, -0.0967,  0.2110, -0.5449,  0.1142,\n",
      "         -0.0376,  0.1503]])\n",
      "tensor([0, 0, 1, 0, 0])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-0.0713,  1.0890, -1.0777,  0.0890, -1.6127,  0.6863, -0.4719, -0.7153,\n",
      "          0.0643,  0.6796],\n",
      "        [-0.5750,  0.1833, -0.8083, -0.3751, -0.7673,  2.1532,  0.8723, -0.8397,\n",
      "          2.1898, -0.5994],\n",
      "        [ 1.1787,  0.0464,  0.7463,  1.0918,  1.2785,  0.0287,  0.1911,  0.6455,\n",
      "         -1.3599,  2.1633],\n",
      "        [ 1.1520,  0.7175,  0.0741, -0.7135, -2.0392, -1.1833, -0.2694,  1.6286,\n",
      "          1.5024, -1.3801],\n",
      "        [ 0.1551,  0.6060,  1.7548,  1.9981, -1.4085, -0.7043, -1.5566, -2.0819,\n",
      "         -1.2804,  1.6965]])\n",
      "tensor([0, 0, 1, 1, 0])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for batch_features, batch_labels in dataloader:\n",
    "\n",
    "    print(batch_features)\n",
    "    print(batch_labels)\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
       "0    842302         M  ...                  0.11890          NaN\n",
       "1    842517         M  ...                  0.08902          NaN\n",
       "2  84300903         M  ...                  0.08758          NaN\n",
       "3  84348301         M  ...                  0.17300          NaN\n",
       "4  84358402         M  ...                  0.07678          NaN\n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
       "0         M        17.99  ...          0.4601                  0.11890\n",
       "1         M        20.57  ...          0.2750                  0.08902\n",
       "2         M        19.69  ...          0.3613                  0.08758\n",
       "3         M        11.42  ...          0.6638                  0.17300\n",
       "4         M        20.29  ...          0.2364                  0.07678\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.33708191, -1.15375641, -0.34056741, ..., -0.89154804,\n",
       "         -0.74701599,  0.93070081],\n",
       "        [-0.57157448, -0.28486479, -0.57789321, ..., -0.9160658 ,\n",
       "         -0.78846335, -0.37508138],\n",
       "        [-0.47834249, -0.5546785 , -0.54100318, ..., -1.36136964,\n",
       "         -1.56799258, -1.23509464],\n",
       "        ...,\n",
       "        [ 0.73367332, -0.10879991,  0.69317294, ...,  0.47072007,\n",
       "         -0.14443512, -0.65216603],\n",
       "        [-0.12236582,  1.02761888, -0.15775686, ..., -0.85231962,\n",
       "         -0.37877213, -1.15379435],\n",
       "        [ 0.06692337,  0.11299611,  0.08571727, ...,  0.61016483,\n",
       "         -0.29109502,  0.52309324]], shape=(455, 30)),\n",
       " 336    B\n",
       " 480    B\n",
       " 315    B\n",
       " 239    M\n",
       " 286    B\n",
       "       ..\n",
       " 427    B\n",
       " 517    M\n",
       " 167    M\n",
       " 243    B\n",
       " 99     M\n",
       " Name: diagnosis, Length: 455, dtype: object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy arrays to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([114, 30]), torch.Size([455]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.shape, y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, features, labels):\n",
    "\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return len(self.features)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.7383, -0.0539, -0.7455, -0.7104, -0.8089, -0.5393, -0.4597, -0.9241,\n",
       "          0.7984, -0.0364, -0.4372,  0.4157, -0.3387, -0.4387,  0.0593, -0.2998,\n",
       "          0.3755, -0.5287, -0.2368, -0.1792, -0.6774,  0.2103, -0.6361, -0.6461,\n",
       "         -0.3652, -0.4023, -0.1098, -0.7668,  0.2142, -0.0681]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "  def __init__(self, num_features):\n",
    "\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(num_features, 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, features):\n",
    "\n",
    "    out = self.linear(features)\n",
    "    out = self.sigmoid(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# define loss function\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.11706425249576569\n",
      "Epoch: 2, Loss: 0.14067991077899933\n",
      "Epoch: 3, Loss: 0.21245799958705902\n",
      "Epoch: 4, Loss: 0.1404586136341095\n",
      "Epoch: 5, Loss: 0.0688457041978836\n",
      "Epoch: 6, Loss: 0.11112374067306519\n",
      "Epoch: 7, Loss: 0.11461646854877472\n",
      "Epoch: 8, Loss: 0.12712877988815308\n",
      "Epoch: 9, Loss: 0.11883382499217987\n",
      "Epoch: 10, Loss: 0.04554257169365883\n",
      "Epoch: 11, Loss: 0.02412101812660694\n",
      "Epoch: 12, Loss: 0.03562203049659729\n",
      "Epoch: 13, Loss: 0.007184027694165707\n",
      "Epoch: 14, Loss: 0.011932742781937122\n",
      "Epoch: 15, Loss: 0.019152788445353508\n",
      "Epoch: 16, Loss: 0.018185468390583992\n",
      "Epoch: 17, Loss: 0.05057894438505173\n",
      "Epoch: 18, Loss: 0.053384535014629364\n",
      "Epoch: 19, Loss: 0.031292837113142014\n",
      "Epoch: 20, Loss: 0.0071564712561666965\n",
      "Epoch: 21, Loss: 0.2796573340892792\n",
      "Epoch: 22, Loss: 0.15290233492851257\n",
      "Epoch: 23, Loss: 0.10286828130483627\n",
      "Epoch: 24, Loss: 0.16980186104774475\n",
      "Epoch: 25, Loss: 0.024532949551939964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = model(batch_features)\n",
    "\n",
    "    # loss calculate\n",
    "    loss = loss_function(y_pred, batch_labels.view(-1,1))\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # parameters update\n",
    "    optimizer.step()\n",
    "\n",
    "  # print loss in each epoch\n",
    "  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9488\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using test_loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.8).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
